{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import benedict\n",
    "\n",
    "import config\n",
    "import pinky\n",
    "\n",
    "client = config.client\n",
    "db = client[config.database]\n",
    "col = db[config.weathers_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_keys(ref, check, as_kv_list=False):\n",
    "    ''' Make sure that the keys for check are the same as those in ref.\n",
    "    \n",
    "    :param ref: the dictionary whose keys are to be referenced\n",
    "    :type ref: dict\n",
    "    :param check: the dict to have its keys checked and uppdated\n",
    "    :type check: dict\n",
    "    '''\n",
    "    \n",
    "    if not as_kv_list:\n",
    "        keys1 = ref.keys()\n",
    "        keys2 = check.keys()\n",
    "    else:\n",
    "        keys1 = [tup[0] for tup in ref]\n",
    "        keys2 = [tup[0] for tup in check]\n",
    "    diff1 = keys2 - keys1  #keys in dict2 that are not in dict1\n",
    "    diff2 = keys1 - keys2  #keys in dict1 that are not in dict2\n",
    "    for item in diff1:\n",
    "        check.pop(item)\n",
    "    for item in diff2:\n",
    "        check[item] = None\n",
    "    return\n",
    "\n",
    "def strip_keys(df):\n",
    "    ''' Take a pandas.DataFrame and replace each dict with the list of\n",
    "    its values.\n",
    "    '''\n",
    "    \n",
    "    t = []\n",
    "    \n",
    "    def dict_strip(x):\n",
    "        ''' Strip the keys from a dict. '''\n",
    "        \n",
    "        if isinstance(x, dict):\n",
    "            return [x for x in x.values()]\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        temp = []\n",
    "        for item in row[1]:\n",
    "            temp.append(dict_strip(item))\n",
    "        t.append(pd.Series(temp, name=row[1].name, dtype=object))\n",
    "    return pd.concat(t, axis=1, ignore_index=False)\n",
    "\n",
    "def compare_dicts(one, the_other, return_type='dict', as_kv_list=False):\n",
    "    ''' Compare the values of two dicts, key by common key. When the values are\n",
    "    numbers, return the difference: when strings, return 0: if the strings are\n",
    "    equal, 0, 1 if they are different: when dicts, run this function: if it's a\n",
    "    list then step through it, running this function on each element: when\n",
    "    NoneType, set it to a flag value.\n",
    "\n",
    "    :params one, the_other: dictionaries with the same set of keys and sub-keys\n",
    "    :type one, the_other: dict\n",
    "    '''\n",
    "    \n",
    "    delta = {}  # The delta document. Contains all the forecast errors\n",
    "    \n",
    "    if as_kv_list:\n",
    "        for (k, v) in one:\n",
    "            try:\n",
    "                # Check and compare dictionaries according to their value type\n",
    "                if type(v) == int or type(v) == float:\n",
    "                    if type(the_other[k]) == int or type(the_other[k]) == float:\n",
    "                        delta[k] = v - the_other[k]\n",
    "                elif type(v) == dict:\n",
    "                    delta[k] = compare_dicts(\n",
    "                        v, the_other[k], return_type='list', as_kv_list=True)\n",
    "                elif type(v) == str:\n",
    "                    if v == the_other[k]:\n",
    "                        delta[k] = 0\n",
    "                    else:\n",
    "                        delta[k] = 1\n",
    "                elif type(v) == list:\n",
    "                    delta[k] = [\n",
    "                        compare_dicts(item, other_item)\n",
    "                        for item, other_item\n",
    "                        in list(zip(v, the_other[k]))\n",
    "                    ]\n",
    "                elif type(v):\n",
    "                    delta[k] = 0\n",
    "            except KeyError as e:\n",
    "                print(f'missing key..... {e}')\n",
    "    else:\n",
    "        for (k, v) in one.items():\n",
    "            try:\n",
    "                # Check and compare dictionaries according to their value type\n",
    "                if type(v) == int or type(v) == float:\n",
    "                    if type(the_other[k]) == int or type(the_other[k]) == float:\n",
    "                        delta[k] = v - the_other[k]\n",
    "                elif type(v) == dict:\n",
    "                    delta[k] = compare_dicts(v, the_other[k], return_type='list')\n",
    "                elif type(v) == str:\n",
    "                    if v == the_other[k]:\n",
    "                        delta[k] = 0\n",
    "                    else:\n",
    "                        delta[k] = 1\n",
    "                elif type(v) == list:\n",
    "                    delta[k] = [\n",
    "                        compare_dicts(item, other_item)\n",
    "                        for item, other_item\n",
    "                        in list(zip(v, the_other[k]))\n",
    "                    ]\n",
    "                elif type(v):\n",
    "                    delta[k] = 0\n",
    "            except KeyError as e:\n",
    "                print(f'missing key..... {e}')\n",
    "    if return_type == 'dict':\n",
    "        return delta\n",
    "    if return_type == 'list':\n",
    "        return [v for v in delta.values()]\n",
    "\n",
    "def tups_to_dict(tups):\n",
    "    ''' Convert a list of tuples to a dictionary. '''\n",
    "    dicti = {}\n",
    "    for a, b in tups:\n",
    "        dicti.setdefault(a, b)\n",
    "    return dicti \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo_to_df(collection, filters={}, limit=None):\n",
    "    ''' Read a MongoDB cursor to a pandas DataFrame.\n",
    "    Arguments are \"collection\", which must be a MongoDB\n",
    "    client.database.collection object, and \"filters\", which\n",
    "    can be a well formed mongo query. \"limit\" will limit\n",
    "    the number of documents returned on the cursor.\n",
    "    '''\n",
    "\n",
    "    documents = collection.find(filters)[:limit]\n",
    "    return pd.DataFrame.from_records([doc for doc in documents])\n",
    "\n",
    "def records_to_rows(col, filters={}, limit=100):\n",
    "    ''' Request records from the database collection and convert it to a\n",
    "    pandas.DataFrame. All records are set with keys as column names and\n",
    "    '_id' as the index.\n",
    "    '''\n",
    "    \n",
    "    docs = col.find(filters, batch_size=100)[:limit]\n",
    "    weathers = pd.DataFrame()\n",
    "    temp = []\n",
    "    for row in docs:\n",
    "        if isinstance(row, dict):\n",
    "            # Lookout for the occurance of a list and handle appropriately.\n",
    "            for v in row.values():\n",
    "                if isinstance(v, list):\n",
    "                    row['weather'] = row['weather'][0]\n",
    "            # These next lines convert the dicts to benedicts before\n",
    "            # flattening, sorting by keys, and then converting back to dicts.\n",
    "            bene = benedict.benedict.flatten(row)\n",
    "            flat_bene = benedict.benedict(bene)\n",
    "            sorted_flat_bene = flat_bene.items_sorted_by_keys()\n",
    "            sorted_flat_dict = tups_to_dict(sorted_flat_bene)\n",
    "            # Store in temp list as a pandas.DataFrame.\n",
    "            temp.append(pd.DataFrame(sorted_flat_dict, index=[row['_id']]))\n",
    "    return pd.concat(temp)\n",
    "\n",
    "def read_mongo_a(col, filters={}, limit=None):\n",
    "    ''' Retrieve data from the Mongo database and transform it to a pandas\n",
    "    DataFrame; return the DataFrame.\n",
    "\n",
    "    :param col: the MongoDB collection to be read\n",
    "    :type collection: pymongo.collection.Collection\n",
    "    :param filters: a well formed MongoDB query\n",
    "    :type filters: dict\n",
    "    :param limit: optional limiter to the number of documents retrieved\n",
    "    :type limit: int\n",
    "    '''\n",
    "\n",
    "    # Shorten the cursor length if limit is given, otherwise get everything;\n",
    "    # transform the retrieved data to a pandas.DataFrame and return it.\n",
    "    docs = col.find(filters)[:limit]\n",
    "    weathers = []\n",
    "    for doc in docs:\n",
    "        if isinstance(doc, dict):\n",
    "            for v in doc.values():\n",
    "                if isinstance(v, list):\n",
    "                    doc['weather'] = doc['weather'][0]\n",
    "        # Convert the dict to a benedict, flatten it, sort it, convert it back\n",
    "        # to a dict, and finally transform the dict to a DataFrame and append\n",
    "        # it to a list to tbe concatted to together.\n",
    "        bene = benedict.benedict(doc).flatten().items_sorted_by_keys()\n",
    "        dic = tups_to_dict(bene)\n",
    "        df = pd.DataFrame.from_dict(dic, orient='index')\n",
    "        weathers.append(df.transpose())\n",
    "    if limit:\n",
    "        print(f'The length of your df has been limited to {limit}.')\n",
    "    return pd.concat(weathers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_item_with_kv_pair(series, key, value):\n",
    "    '''Find and return the first item in a given pandas Series that has the\n",
    "    given key-value pair.\n",
    "    \n",
    "    :param series: a pandas series\n",
    "    :type series: pandas.Series\n",
    "    :param key: the key the function should search for\n",
    "    :type key: str\n",
    "    :param value: the value the function should compare to\n",
    "    :type value: I think anything that '==' can be used with\n",
    "    \n",
    "    :returns: the object found or None or raises TypeError\n",
    "    '''\n",
    "    \n",
    "    if isinstance(series, pd.Series):\n",
    "        for item in series:\n",
    "            if isinstance(item, dict):\n",
    "                if key in item:\n",
    "                    if item[key] == value:\n",
    "                        return item\n",
    "            elif isinstance(item, list):\n",
    "                for elem in item:\n",
    "                    if elem[0] == key:\n",
    "                        if elem[1] == value:\n",
    "                            return item\n",
    "        return None\n",
    "    else:\n",
    "        raise TypeError(\"find_item_with_key() wants a pandas.Series.\")\n",
    "        return\n",
    "    \n",
    "def flatten_to_series(df):\n",
    "    ''' A function to convert a DataFrame to a Series.\n",
    "    This function takes each row of the dataframe and represents it as a\n",
    "    Series with a given index made by the string concatenation of the row\n",
    "    number and the column name.\n",
    "    \n",
    "    :param df: the dataframe to be flattened\n",
    "    :type df: pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    index = []\n",
    "    data = []\n",
    "    for row in df.iterrows():\n",
    "        for d, i in zip(row[1], row[1].index):\n",
    "            index.append(str(i)+str(row[0]))\n",
    "            data.append(d)\n",
    "    d = pd.DataFrame(data, index=index)\n",
    "    return d\n",
    "\n",
    "def flatten_to_single_row(df):\n",
    "    ''' A function to convert a DataFrame to a single row DataFrame.\n",
    "    This function takes each row of the dataframe and represents it as a\n",
    "    single DataFrame row with a given index made by the string concatenation\n",
    "    of the row number and the column name.\n",
    "    \n",
    "    :param df: the dataframe to be flattened\n",
    "    :type df: pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    index = []\n",
    "    data = []\n",
    "    for row in df.iterrows():\n",
    "        for d, i in zip(row[1], row[1].index):\n",
    "            index.append(str(i)+str(row[0]))\n",
    "            data.append(d)\n",
    "    d = pd.DataFrame(data, index=index)\n",
    "    return d.transpose()\n",
    "\n",
    "def flat_and_concat(flist):\n",
    "    ''' Flatten a list of DataFrames and concat the flattened versions\n",
    "    together and return as a single DataFrame.\n",
    "    \n",
    "    This is useful when you have a list of DataFrames, each of them\n",
    "    representing a collection of related dataset\n",
    "    \n",
    "    :param flist: At list of pandas.DataFrames.\n",
    "    :type flist: list\n",
    "    '''\n",
    "    D = []\n",
    "    if not isinstance(flist, list):\n",
    "        raise TypeError('flat_and_concat() has to have a list of DataFrames.')\n",
    "        return\n",
    "    for item in flist:\n",
    "        if isinstance(item, pandas.DataFrame):\n",
    "            D.append(flatten_to_single_row(item))\n",
    "    return pd.concat(D)\n",
    "\n",
    "def make_instants(df, _return=True):\n",
    "    ''' Convert the rows of the weathers collection DataFrame to a DataFrame of\n",
    "    instants.\n",
    "    \n",
    "    This is useful when you have a DataFrame already built from rows of raw \n",
    "    data representing individual documents as they came from the database and\n",
    "    you want to create a DataFrame of flattened DataFrames\n",
    "    '''\n",
    "    \n",
    "    d = []\n",
    "    timeplaces = df.index.unique(level='timeplace')\n",
    "    for tp in timeplaces:\n",
    "        temp_df = df.loc[tp]\n",
    "        d.append(flatten_to_single_row(temp_df))\n",
    "    if _return:\n",
    "        return pd.concat(d)\n",
    "    else:\n",
    "        np.save('instants.npy', pd.concat(d))\n",
    "        return\n",
    "\n",
    "def make_inst(df):\n",
    "    ''' Create instant Series from the DataFrame: step through each row of the\n",
    "    DataFrame and check the count of the row. If it is 42 or more, drop any na\n",
    "    values, flatten each dict and append the Series to a new DataFrame and\n",
    "    return it.\n",
    "    '''\n",
    "    \n",
    "    instants = []\n",
    "    for row in df.iterrows():\n",
    "        if row[1].count() <= 37:\n",
    "            continue\n",
    "        row[1].dropna(inplace=True)\n",
    "#         row[1].name = row[0]\n",
    "        obs = find_item_with_kv_pair(row[1], 'type', 'obs')\n",
    "        for item in row[1].iteritems():\n",
    "            if isinstance(item[1], dict):\n",
    "                for v in item[1].values():\n",
    "                    if isinstance(v, list):\n",
    "                        item[1]['weather'] = item[1]['weather'][0]\n",
    "                if obs != None:\n",
    "                    if item[1]['type'] == 'cast':\n",
    "                        update_keys(item[1], obs)\n",
    "            if isinstance(item[1], list) and obs != None:\n",
    "                if item[1][0] == 'cast':\n",
    "                    update_keys(item[1], obs)\n",
    "        # These next lines convert the dicts to benedicts before flattening,\n",
    "        # sorting by keys, and then converting back to dicts.\n",
    "        flat_data = row[1].apply(benedict.benedict.flatten)\n",
    "        sorted_items = flat_data.apply(benedict.benedict.items_sorted_by_keys)\n",
    "        flat_sorted_data = sorted_items.apply(tups_to_dict)\n",
    "        instants.append(flat_sorted_data)\n",
    "    instants = pd.concat(instants, axis=1, ignore_index=False).transpose()\n",
    "    np.save('instants.npy', instants)\n",
    "    return instants\n",
    "\n",
    "def make_data(series):\n",
    "    ''' Take a pandas.Series and compare each of the items to one of the other\n",
    "    items (dict comparisons) and return a pandas.Series of comparison results.\n",
    "    '''\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    def key_strip(x):\n",
    "        ''' Strip the keys from a dict. '''\n",
    "\n",
    "        if isinstance(x, dict):\n",
    "            return [x for x in x.values()]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    for item in series.iteritems():\n",
    "        if isinstance(item[1], dict):\n",
    "            data.append(key_strip(item[1]))\n",
    "    return pd.Series(data, name=series.name, dtype=object)\n",
    "\n",
    "def make_data_df(df):\n",
    "    ''' Create the DataFrame that will contain the data to be used as the\n",
    "    Data dataset to go along with the Target dataset. First make the instants\n",
    "    DataFrame, then go through it row by row and remove all the items that\n",
    "    are observation data. Finally save.\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    for row in df.iterrows():\n",
    "#         data.append(make_data(row[0]))\n",
    "#         row[1].name = row[0]\n",
    "        obs = find_item_with_kv_pair(row[1], 'type', 'obs')\n",
    "        for item in row[1].iteritems():\n",
    "            if isinstance(item[1], dict):\n",
    "                if obs != None:\n",
    "                    if item[1]['type'] == 'obs':\n",
    "#                         print(item)\n",
    "                        row[1].pop(item[0])\n",
    "                        break\n",
    "        data.append(make_data(row[1]))\n",
    "    data_df = pd.concat(data, axis=1, ignore_index=False).transpose()\n",
    "#     data_df = strip_keys(data_df)#.transpose()\n",
    "    np.save('forecast_values.npy', data_df)\n",
    "    return data_df\n",
    "    \n",
    "\n",
    "def make_deltas(series):\n",
    "    ''' Take a pandas.Series and compare each of the items to one of the other\n",
    "    items (dict comparisons) and return a pandas.Series of comparison results.\n",
    "    '''\n",
    "\n",
    "    deltas = []\n",
    "    obs = find_item_with_kv_pair(series, 'type', 'obs')\n",
    "    for item in series:\n",
    "        if isinstance(item, dict) and obs != None:\n",
    "            if item['type'] == 'cast':\n",
    "                update_keys(item, obs)\n",
    "                deltas.append(compare_dicts(obs, item, return_type='list'))\n",
    "        if isinstance(item, list) and obs != None:\n",
    "            if item[0] == 'cast':\n",
    "                update_keys(item, obs)\n",
    "                deltas.append(compare_dicts(obs, item, return_type='list'))\n",
    "    return pd.Series(deltas, name=series.name, dtype=object)\n",
    "\n",
    "def make_deltas_df(df):\n",
    "    ''' Build the complete deltas DataFrame. '''\n",
    "    \n",
    "    deltas = []\n",
    "    deltas_df = pd.DataFrame()\n",
    "    \n",
    "    # Create a DataFrame of the delta documemnts derived from the rows of\n",
    "    # the supplied DataFrame. Add the DataFrame to a list so that it all\n",
    "    # concatinates to a DataFrame. Then, row by row create the \"deltas\" for\n",
    "    # the data and add it to the list. Finally concat all that together.\n",
    "    deltas.append(deltas_df)\n",
    "    for row in df.iterrows():\n",
    "        deltas.append(make_deltas(row[1]))\n",
    "    deltas_df = pd.concat(deltas, axis=1, ignore_index=False).transpose()\n",
    "    np.save('delta_values.npy', deltas_df)\n",
    "    return deltas_df\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw_recs = col.find({})\n",
    "count = col.count_documents({})\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "limit = 1000\n",
    "timeplaces = set([doc['timeplace'] for doc in raw_recs])\n",
    "len(timeplaces)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('timeplaces.txt', 'w') as tp:\n",
    "    for row in timeplaces:\n",
    "        tp.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# col.create_index([('timeplace', pymongo.ASCENDING)])\n",
    "tpd = [doc for doc in col.find({'timeplace': 'dnhzms0000001599091200'})]\n",
    "len(tpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {'timeplace': 'dnhzms0000001599091200'}\n",
    "\n",
    "rdf = records_to_rows(col, filters, limit=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "records_df = records_to_rows(col, limit=10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "records1 = records_to_rows(col, limit=10)\n",
    "records1.head(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "records_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "records_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rdf = records_df\n",
    "# rdf.shape\n",
    "rdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinky\n",
    "\n",
    "drop_cols = ['_id',\n",
    "             'base',\n",
    "             'dt',\n",
    "             'cod',\n",
    "             'coord_lat',\n",
    "             'coord_lon',\n",
    "             'sys_type',\n",
    "             'dt_txt',\n",
    "             'pop',\n",
    "             'sys_pod',\n",
    "             'weather_description',\n",
    "             'weather_icon',\n",
    "             'weather_id',\n",
    "             'weather_main'\n",
    "            ]\n",
    "rdf.drop(columns=drop_cols, inplace=True)\n",
    "rdf['tt_inst'] = rdf.loc[:, 'tt_inst'].apply(pinky.favor, trans=False)\n",
    "rdf.set_index(['timeplace', 'tt_inst', 'type'], inplace=True)\n",
    "rdf.sort_index(inplace=True)\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "instants = []\n",
    "tps = []\n",
    "with open('legits.txt', 'r') as tp:\n",
    "    for row in tp:\n",
    "        tps.append(row.strip('\\n'))\n",
    "\n",
    "def sort_out_inst(tps, limit=None):\n",
    "    '''  '''\n",
    "    \n",
    "    instants = []\n",
    "    legits = []\n",
    "    wtfs = []\n",
    "    not_legits = []\n",
    "    for row in list(tps)[:limit]:\n",
    "        filters = {'timeplace': row.strip('\\n')}\n",
    "        rdf = records_to_rows(col, filters, limit=None)\n",
    "        if len(rdf.index) == 40:\n",
    "            drop_cols = ['_id',\n",
    "    #              'base',\n",
    "                'dt',\n",
    "    #              'cod',\n",
    "    #              'coord_lat',\n",
    "    #              'coord_lon',\n",
    "    #              'sys_type',\n",
    "                 'dt_txt',\n",
    "                 'pop',\n",
    "                 'sys_pod',\n",
    "                 'weather_description',\n",
    "                 'weather_icon',\n",
    "                 'weather_id',\n",
    "                 'weather_main'\n",
    "                ]\n",
    "            rdf.drop(columns=drop_cols, inplace=True)\n",
    "            rdf['tt_inst'] = rdf.loc[:, 'tt_inst'].apply(pinky.favor, trans=False)\n",
    "            rdf.set_index(['timeplace', 'tt_inst', 'type'], inplace=True)\n",
    "            rdf.sort_index(inplace=True)\n",
    "            instants.append(rdf)\n",
    "            legits.append(row)\n",
    "        elif 'obs' in rdf['type'].values:\n",
    "            not_legits.append(row)\n",
    "        else:\n",
    "            wtfs.append(row)\n",
    "        with open('legits.txt', 'w') as leg:\n",
    "            for l in legits:\n",
    "                leg.write(l+'\\n')\n",
    "        with open('not_legits.txt', 'w') as nl:\n",
    "            for l in not_legits:\n",
    "                nl.write(l+'\\n')\n",
    "        with open('wtfs.txt', 'w') as wtf:\n",
    "            for l in wtfs:\n",
    "                wtf.write(l+'\\n')\n",
    "    return pd.concat(legits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "lst = []\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "with open('legits.txt', 'r') as l:\n",
    "    for i in l:#range(2):\n",
    "        lst.append(i)\n",
    "print(str(lst))\n",
    "# grouper(str(lst), 22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = sort_out_inst(timeplaces, limit=10000)\n",
    "inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df = make_instants(instants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tt_inst0</th>\n",
       "      <th>type0</th>\n",
       "      <th>clouds_all0</th>\n",
       "      <th>instant0</th>\n",
       "      <th>location_lat0</th>\n",
       "      <th>location_lon0</th>\n",
       "      <th>main_feels_like0</th>\n",
       "      <th>main_grnd_level0</th>\n",
       "      <th>main_humidity0</th>\n",
       "      <th>main_pressure0</th>\n",
       "      <th>...</th>\n",
       "      <th>coord_lon40</th>\n",
       "      <th>id40</th>\n",
       "      <th>name40</th>\n",
       "      <th>sys_country40</th>\n",
       "      <th>sys_id40</th>\n",
       "      <th>sys_sunrise40</th>\n",
       "      <th>sys_sunset40</th>\n",
       "      <th>sys_type40</th>\n",
       "      <th>timezone40</th>\n",
       "      <th>rain_1h40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>obs</td>\n",
       "      <td>25</td>\n",
       "      <td>1599091200</td>\n",
       "      <td>35.05</td>\n",
       "      <td>-83.08</td>\n",
       "      <td>297.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>1013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cast</td>\n",
       "      <td>99</td>\n",
       "      <td>1600916400</td>\n",
       "      <td>34.83</td>\n",
       "      <td>-84.35</td>\n",
       "      <td>288.46</td>\n",
       "      <td>954.00</td>\n",
       "      <td>90</td>\n",
       "      <td>1017</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151200</td>\n",
       "      <td>cast</td>\n",
       "      <td>8</td>\n",
       "      <td>1601089200</td>\n",
       "      <td>33.99</td>\n",
       "      <td>-83.39</td>\n",
       "      <td>294.81</td>\n",
       "      <td>994.00</td>\n",
       "      <td>97</td>\n",
       "      <td>1016</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151200</td>\n",
       "      <td>cast</td>\n",
       "      <td>100</td>\n",
       "      <td>1598626800</td>\n",
       "      <td>34.04</td>\n",
       "      <td>-83.12</td>\n",
       "      <td>305.22</td>\n",
       "      <td>997.00</td>\n",
       "      <td>67</td>\n",
       "      <td>1017</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cast</td>\n",
       "      <td>35</td>\n",
       "      <td>1600797600</td>\n",
       "      <td>34.34</td>\n",
       "      <td>-84.05</td>\n",
       "      <td>293.00</td>\n",
       "      <td>981.00</td>\n",
       "      <td>47</td>\n",
       "      <td>1025</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tt_inst0 type0 clouds_all0    instant0 location_lat0 location_lon0  \\\n",
       "0        0   obs          25  1599091200         35.05        -83.08   \n",
       "0        0  cast          99  1600916400         34.83        -84.35   \n",
       "0   151200  cast           8  1601089200         33.99        -83.39   \n",
       "0   151200  cast         100  1598626800         34.04        -83.12   \n",
       "0        0  cast          35  1600797600         34.34        -84.05   \n",
       "\n",
       "  main_feels_like0 main_grnd_level0 main_humidity0 main_pressure0  ...  \\\n",
       "0           297.55              NaN             70           1013  ...   \n",
       "0           288.46           954.00             90           1017  ...   \n",
       "0           294.81           994.00             97           1016  ...   \n",
       "0           305.22           997.00             67           1017  ...   \n",
       "0           293.00           981.00             47           1025  ...   \n",
       "\n",
       "  coord_lon40 id40 name40 sys_country40 sys_id40 sys_sunrise40 sys_sunset40  \\\n",
       "0         NaN  NaN    NaN           NaN      NaN           NaN          NaN   \n",
       "0         NaN  NaN    NaN           NaN      NaN           NaN          NaN   \n",
       "0         NaN  NaN    NaN           NaN      NaN           NaN          NaN   \n",
       "0         NaN  NaN    NaN           NaN      NaN           NaN          NaN   \n",
       "0         NaN  NaN    NaN           NaN      NaN           NaN          NaN   \n",
       "\n",
       "  sys_type40 timezone40 rain_1h40  \n",
       "0        NaN        NaN       NaN  \n",
       "0        NaN        NaN       NaN  \n",
       "0        NaN        NaN       NaN  \n",
       "0        NaN        NaN       NaN  \n",
       "0        NaN        NaN       NaN  \n",
       "\n",
       "[5 rows x 1312 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tt_inst0</th>\n",
       "      <th>base0</th>\n",
       "      <th>clouds_all0</th>\n",
       "      <th>cod0</th>\n",
       "      <th>coord_lat0</th>\n",
       "      <th>coord_lon0</th>\n",
       "      <th>id0</th>\n",
       "      <th>instant0</th>\n",
       "      <th>location_lat0</th>\n",
       "      <th>location_lon0</th>\n",
       "      <th>...</th>\n",
       "      <th>timezone0</th>\n",
       "      <th>type0</th>\n",
       "      <th>visibility0</th>\n",
       "      <th>wind_deg0</th>\n",
       "      <th>wind_speed0</th>\n",
       "      <th>main_grnd_level0</th>\n",
       "      <th>main_sea_level0</th>\n",
       "      <th>main_temp_kf0</th>\n",
       "      <th>rain_3h0</th>\n",
       "      <th>rain_1h0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>25</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>1,000.00</td>\n",
       "      <td>1,000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1,000.00</td>\n",
       "      <td>975.00</td>\n",
       "      <td>975.00</td>\n",
       "      <td>975.00</td>\n",
       "      <td>461.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>41</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>167</td>\n",
       "      <td>333.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>248.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>140400</td>\n",
       "      <td>stations</td>\n",
       "      <td>100</td>\n",
       "      <td>200.00</td>\n",
       "      <td>33.82</td>\n",
       "      <td>-84.22</td>\n",
       "      <td>4,218,165.00</td>\n",
       "      <td>1598119200</td>\n",
       "      <td>33.82</td>\n",
       "      <td>-84.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-14,400.00</td>\n",
       "      <td>cast</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>983.00</td>\n",
       "      <td>1,016.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>325</td>\n",
       "      <td>25.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>25</td>\n",
       "      <td>328.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>20</td>\n",
       "      <td>21.00</td>\n",
       "      <td>111.00</td>\n",
       "      <td>234.00</td>\n",
       "      <td>876.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tt_inst0     base0  clouds_all0   cod0  coord_lat0  coord_lon0  \\\n",
       "count       1000        25         1000  25.00       25.00       25.00   \n",
       "unique        41         1           81   1.00        4.00        8.00   \n",
       "top       140400  stations          100 200.00       33.82      -84.22   \n",
       "freq          25        25          325  25.00        8.00        4.00   \n",
       "\n",
       "                id0    instant0  location_lat0  location_lon0  ...  timezone0  \\\n",
       "count         25.00        1000       1,000.00       1,000.00  ...      25.00   \n",
       "unique        17.00          41           4.00           8.00  ...       1.00   \n",
       "top    4,218,165.00  1598119200          33.82         -84.22  ... -14,400.00   \n",
       "freq           2.00          25         328.00         164.00  ...      25.00   \n",
       "\n",
       "        type0  visibility0  wind_deg0  wind_speed0  main_grnd_level0  \\\n",
       "count    1000         1000       1000     1,000.00            975.00   \n",
       "unique      2           26        167       333.00             20.00   \n",
       "top      cast        10000          0         1.50            983.00   \n",
       "freq      975          975         20        21.00            111.00   \n",
       "\n",
       "       main_sea_level0 main_temp_kf0  rain_3h0  rain_1h0  \n",
       "count           975.00        975.00    461.00      2.00  \n",
       "unique            9.00         62.00    248.00      2.00  \n",
       "top           1,016.00          0.00      0.31      0.15  \n",
       "freq            234.00        876.00     10.00      1.00  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in inst_df.columns:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data_df(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_deltas_df(inst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
