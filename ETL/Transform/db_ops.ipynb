{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongo.database import Database\n",
    "from pymongo.collection import Collection, ReturnDocument\n",
    "from pymongo.errors import ConnectionFailure, InvalidDocument, DuplicateKeyError, OperationFailure, ConfigurationError\n",
    "from urllib.parse import quote\n",
    "\n",
    "from config import user, password, socket_path, host, port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Client(host=None, port=None, uri=None):\n",
    "    ''' Create and return a pymongo MongoClient object. Connect with the given parameters if possible, switch to local if the\n",
    "    remote connection is not possible, using the default host and port.\n",
    "    \n",
    "    :param host: the local host to be used. defaults within to localhost\n",
    "    :type host: sting\n",
    "    :param port: the local port to be used. defaults within to 27017\n",
    "    :type port: int\n",
    "    :param uri: the remote server URI. must be uri encoded\n",
    "    type uri: uri encoded sting'''\n",
    "    \n",
    "    if host and port:\n",
    "        try:\n",
    "            client = MongoClient(host=host, port=port)\n",
    "            return client\n",
    "        except ConnectionFailure:\n",
    "            # connect to the remote server if a valid uri is given\n",
    "            if uri:\n",
    "                print('caught ConnectionFailure on local server. Trying to make it with remote')\n",
    "                client = MongoClient(uri)\n",
    "                print(f'established remote MongoClient on URI={uri}')\n",
    "                return client\n",
    "            print('caught ConnectionFailure on local server. Returning None')\n",
    "            return None\n",
    "    elif uri:\n",
    "        # verify that the connection with the remote server is active and switch to the local server if it's not\n",
    "        try:\n",
    "            client = MongoClient(uri)\n",
    "            return client\n",
    "        except ConfigurationError:\n",
    "            print(f'Caught configurationError in client() for URI={uri}. It was likely triggered by a DNS timeout.')\n",
    "            client = MongoClient(host=host, port=port)\n",
    "            print('connection made with local server, even though you asked for the remote server')\n",
    "            return client\n",
    "\n",
    "def dbncol(client, collection, database='test'):\n",
    "    ''' Make a connection to the database and collection given in the arguments.\n",
    "\n",
    "    :param client: a MongoClient instance\n",
    "    :type client: pymongo.MongoClient\n",
    "    :param database: the name of the database to be used. It must be a database name present at the client\n",
    "    :type database: str\n",
    "    :param collection: the database collection to be used.  It must be a collection name present in the database\n",
    "    :type collection: str\n",
    "    \n",
    "    :return col: the collection to be used\n",
    "    :type: pymongo.collection.Collection\n",
    "    '''\n",
    "\n",
    "    db = Database(client, database)\n",
    "    col = Collection(db, collection)\n",
    "    return col\n",
    "\n",
    "def move_sorted(client, from_db, from_col, to_db, to_col, id_list):\n",
    "    ''' Move the documents from the active database to the archive database.\n",
    "    Once the forecasted and observed weather objects are sorted into instant documents and loaded \n",
    "    to the insants collection they can be moved for permanent storage to another database that will \n",
    "    contain only previously sorted weather documents.\n",
    "    '''\n",
    "\n",
    "    from_db = from_db\n",
    "    from_col = from_col\n",
    "    to_db = to_db\n",
    "    to_col = to_col\n",
    "\n",
    "    from_collection = datollection(client, from_db, form_col)\n",
    "    to_collection = datollection(client, to_db, to_col)\n",
    "\n",
    "    deleted = from_collection.delete_many(id_list)\n",
    "    print(type(deleted))\n",
    "    inserted = to_collection.insert_many(deleted)\n",
    "    print(type(inserted))\n",
    "    \n",
    "def load(data, client, database, collection):\n",
    "    ''' Load data to specified database collection. Also checks for a preexisting document with the same instant and \n",
    "    zipcode, and updates it in the case that there was already one there.\n",
    "\n",
    "    :param data: the dictionary created from the api calls\n",
    "    :type data: dict\n",
    "    :param client: a MongoClient instance\n",
    "    :type client: pymongo.MongoClient\n",
    "    :param database: the database to be used\n",
    "    :type database: str\n",
    "    :param collection: the database collection to be used\n",
    "    :type collection: str\n",
    "    '''\n",
    "\n",
    "    col = dbncol(client, collection, database='test1')\n",
    "\n",
    "    # set the appropriate database collections, filters and update types\n",
    "    if collection == 'instant':\n",
    "        filters = {'zipcode':data['zipcode'], 'instant':data['instant']}\n",
    "        updates = {'$push': {'forecasts': data}} # append the forecast object to the forecasts list\n",
    "        try:\n",
    "            # check to see if there is a document that fits the parameters. If there is, update it, if there isn't, upsert it\n",
    "            return col.find_one_and_update(filters, updates,  upsert=True)\n",
    "        except DuplicateKeyError:\n",
    "            return(f'DuplicateKeyError, could not insert data into {collection}.')\n",
    "    elif collection == 'observed' or collection == 'forecasted':\n",
    "        try:\n",
    "            col.insert_one(data)\n",
    "            return\n",
    "        except DuplicateKeyError:\n",
    "            return(f'DuplicateKeyError, could not insert data into {collection}.')\n",
    "    else:\n",
    "        try:\n",
    "            filters = {'zipcode':data['zipcode'], 'instant':data['instant']}\n",
    "            updates = {'$set': {'forecasts': data}} # append the forecast object to the forecasts list\n",
    "            return col.find_one_and_update(filters, updates,  upsert=True)\n",
    "        except DuplicateKeyError:\n",
    "            return(f'DuplicateKeyError, could not insert data into {collection}.')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "__name__ = 'j'\n",
    "if __name__ == \"__main__\":\n",
    "    filename = './sorted_cast_ids.txt'\n",
    "    sorted_ids = []\n",
    "    with open(filename) as f:\n",
    "        for row in f:\n",
    "            sorted_ids.append(row)\n",
    "    host = host\n",
    "    port = port\n",
    "    database = 'OWM'\n",
    "    collection = 'instant'\n",
    "\n",
    "    client = Client(host=host, port=port)\n",
    "    col = dbncol(client, database=database, collection=collection)\n",
    "    updated_doc_ids = []\n",
    "    result = col.find({}).batch_size(10)\n",
    "    r = result\n",
    "    # change each document in restored instant collection. ** many, maybe all, the documents have all the fields for the observation\n",
    "    # separtely key'd in the parent document. This will put each of those weather fields together under the field 'observation'\n",
    "    from pprint import pprint\n",
    "    i, n = 0, 0\n",
    "    fs_and_us = {'passed' : 0, 'replaced' : 0, 'updated' : 0} # for counting the loop results\n",
    "    for item in r:\n",
    "        if item['_id'] in sorted_ids:\n",
    "            i+=1\n",
    "            continue\n",
    "        if n%200 == 0:\n",
    "            print(f'processed {n} documents')\n",
    "        try:\n",
    "            ref_time = item.pop('reference_time')\n",
    "            item['observed'] = {\n",
    "                'clouds' : item.pop('clouds'),\n",
    "                'detailed_status' : item.pop('detailed_status'),\n",
    "                'humidity' : item.pop('humidity'),\n",
    "                'pressure' : item.pop('pressure'),\n",
    "                'rain' : item.pop('rain'),\n",
    "                'snow' : item.pop('snow'),\n",
    "                'status' : item.pop('status'),\n",
    "                'temperature' : item.pop('temperature'),\n",
    "                'weather_code' : item.pop('weather_code'),\n",
    "                'wind' : item.pop('wind'),\n",
    "                'time_to_instant': item['instant']-ref_time\n",
    "            }\n",
    "            n+=1\n",
    "        except KeyError:\n",
    "            updated_doc_ids.append(item['_id'])\n",
    "            fs_and_us['passed'] += 1\n",
    "            n+=1\n",
    "            continue\n",
    "        filters = {'zipcode':item['zipcode'], 'instant':item['instant']}\n",
    "        updates = {'$set': item}\n",
    "        try:\n",
    "            col.find_one_and_replace(filters, item, upsert=True)\n",
    "    #         print('found and replaced')\n",
    "            fs_and_us['replaced'] += 1\n",
    "        except DuplicateKeyError:\n",
    "            col.find_one_and_update(filters, updates, upsert=True)\n",
    "            fs_and_us['updated'] += 1\n",
    "        updated_doc_ids.append(item['_id'])\n",
    "        n += 1\n",
    "        if n == 120000:\n",
    "            print(f'n=120000 and i={i}. Breaking out')\n",
    "            break\n",
    "    with open(filename, 'w') as f:\n",
    "        for row in updated_doc_ids:\n",
    "            f.write(str(row)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'updated_doc_ids' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-68d560fa0f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_doc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'updated_doc_ids' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(updated_doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-40efe2385010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('env': venv)",
   "language": "python",
   "name": "python37364bitenvvenv4a9201e1e72848cf811a9f7702fb1125"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}