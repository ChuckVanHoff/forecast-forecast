{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the password just got url encoded in Learn.config\n",
      "printing uri from Learn.config-- mongodb+srv://chuckvanhoff:Fe7ePrX%215L5Wh6W@cluster0-anhr9.mongodb.net/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import config\n",
    "import overalls\n",
    "import weather\n",
    "import benedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _connect_mongo(uri, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if uri:\n",
    "        conn = MongoClient(uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "    return conn[db]\n",
    "\n",
    "def read_mongo_to_df(uri, db, collection, query={}, limit=None):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    con = _connect_mongo(uri, db)\n",
    "    # Make a query to the specific DB and Collection\n",
    "    if limit:\n",
    "        cursor = con[collection].find(query)\n",
    "        cursor = cursor[limit]\n",
    "        print(f'number of indexes created has been limited to {limit} ..........................')\n",
    "    else:\n",
    "        cursor = con[collection].find(query)\n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df = pd.DataFrame.from_dict(cursor, orient='index')\n",
    "    return df.transpose()\n",
    "\n",
<<<<<<< HEAD
    "### ORIGINAL ###\n",
    "# def forecast_fields(row):\n",
    "#     row['rain_3h'] = row['rain'].get('3h', 0)\n",
    "#     row['rain_1h'] = row['rain'].get('1h', row['rain_3h'] / 3)\n",
    "#     del row['rain']\n",
    "#     return row\n",
    "### ORIGINAL ###\n",
    "\n",
    "### COPY OF ORIGINAL ###\n",
    "def forecast_fields(row):\n",
    "    row['rain_3h'] = row['rain'].get('3h', row['rain'].get('1h', 0) * 3)\n",
    "    row['rain_1h'] = row['rain'].get('1h', row['rain_3h'] / 3)\n",
    "    del row['rain']\n",
    "    return row\n",
    "### COPY OF ORIGINAL ###\n",
    "\n",
    "def read_mongo_a(uri, db, collection, limit=None, squash=False):\n",
=======
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import overalls\n",
    "import weather\n",
    "import benedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2224e21158e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'27606'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'observation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/forecast-forecast/Learn/weather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, location, _type, data)\u001b[0m\n\u001b[1;32m     85\u001b[0m         }\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m### Added new update function ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moveralls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/forecast-forecast/Learn/overalls.py\u001b[0m in \u001b[0;36mupdate_nested\u001b[0;34m(d, u)\u001b[0m\n\u001b[1;32m     64\u001b[0m     '''\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "w = weather.Weather('27606', 'observation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'DEFAULT', 'clouds': 'DEFAULT', 'rain': {'1h': 0, '3h': 0}, 'snow': {'1h': 0, '3h': 0}, 'wind': {'speed': 0, 'deg': 0}, 'humidity': 'DEFAULT', 'pressure': {'press': 'DEFAULT', 'sea_level': 'DEFAULT'}, 'temperature': {'temp': 'DEFAULT', 'temp_max': 'DEFAULT', 'temp_min': 'DEFAULT'}, 'status': 'DEFAULT', 'detailed_status': 'DEFAULT', 'weather_code': 'DEFAULT', 'visibility_distance': 0, 'dewpoint': 'DEFAULT', 'humidex': 'DEFAULT', 'heat_index': 'DEFAULT', 'time_to_instant': 'DEFAULT'}\n"
     ]
    }
   ],
   "source": [
    "print(w.weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of indexes created has been limited to 5 ..........................\n"
     ]
    }
   ],
   "source": [
    "collection = 'legit_inst'\n",
    "db = 'owmap'\n",
    "df = read_mongo(config.uri, db, collection, no_id=False, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo_a(uri, db, collection, limit=None):\n",
>>>>>>> fixdeep
    "    ''' Retrieve data from the Mongo database and transform it to a pandas\n",
    "    DataFrame; return the DataFrame.\n",
    "\n",
    "    :param collection: the collection name\n",
    "    :type collection: string\n",
    "    :param limit: optional limiter to the number of documents retrieved. '''\n",
    "    \n",
    "    database = _connect_mongo(config.uri, db)\n",
    "    col = {}\n",
    "    \n",
    "    cursor = database[collection].find({})\n",
    "    # Shorten the cursor length if limit is given, otherwise get everything;\n",
    "    # transform the retrieved data to a pandas.DataFrame and return it.\n",
    "    dfs = []\n",
    "    for doc in cursor[:limit]:\n",
    "        \n",
    "        ### trying to add the squash option to the DataFrame fields\n",
    "        if squash:\n",
    "            doc['weather'] = benedict.benedict(doc['weather']).flatten()\n",
    "            doc['forecasts'] = [benedict.benedict(cast) for cast in doc['forecasts']]\n",
    "        ### trying to add the squash option to the DataFrame fields\n",
    "        \n",
    "        dfs.append(\n",
    "            pd.DataFrame.from_dict([{\n",
    "                'zipcode': doc['zipcode'],\n",
    "                'instant': doc['instant'],\n",
    "                'type': 'weather',\n",
    "                **doc['weather']\n",
    "            }], orient='columns')  \n",
    "### don't need the apply if the dict is flattented-- .apply(forecast_fields, axis=1)\n",
    "        )\n",
    "        dfs.append(\n",
    "            pd.DataFrame.from_dict(\n",
    "                [{\n",
    "                    'zipcode': doc['zipcode'],\n",
    "                    'instant': doc['instant'],\n",
    "                    'type': 'forecast',\n",
    "                    **forecast\n",
    "                 } for forecast in doc['forecasts']]\n",
    "            ).apply(forecast_fields, axis=1)\n",
    "        )\n",
    "    if limit:\n",
    "        print(f'The length of your df has been limited to {limit}.')\n",
    "\n",
    "    return pd.concat(dfs).set_index(['zipcode', 'instant', 'time_to_instant'], drop=True)\n",
    "    \n",
    "    # Let the user know that even though there were no errors the DataFrame\n",
    "    # was not created.\n",
    "    return 'From read_mongo(): There were no errors, but your dataframe was \\\n",
    "    not created.'\n",
    "\n",
    "\n",
    "def errors(casts, obs):\n",
    "    ''' Make a dict of errors for the forecasts. Any dicts in the arguments\n",
    "    will be flattened before comparison.\n",
    "    \n",
    "    :param casts: a list of dictionaries\n",
    "    :param obs: a dictionary\n",
    "    \n",
    "    * For best results all dicts should have all the same keys and subkeys.\n",
    "    '''\n",
    "    \n",
    "    # Flatten all dicts and compare. Add the comparisons to a list and return.\n",
    "    casts = [overalls.flatten_dict(cast) for cast in casts]\n",
    "    obs = overalls.flatten_dict(obs)\n",
    "    return [overalls.compare_dicts(cast, obs) for cast in casts]\n",
    "\n",
    "def gen_errs_df(df):\n",
    "    ''' Create an errors dataframe from the argument.\n",
    "    \n",
    "    :param df: Must be a pandas DataFrame.\n",
    "    '''\n",
    "    ### is there a way to step through three lists together? ###\n",
    "    errs_list = []\n",
    "    errs_dict = {}\n",
    "    # Create the error dicts list to be added to the errs_dict.\n",
    "    for (obs, casts) in zip(df['weather'], df['forecasts']): ### this creates a the list of errors from each instant\n",
    "        errs_list.append(errors(casts, obs))\n",
    "    for (_id, errs) in zip(df['_id'], errs_list):  ### this creates a dict from the errors list with the index as key\n",
    "        errs_dict[_id] = errs\n",
    "    dd = pd.DataFrame.from_dict(errs_dict, orient='index')\n",
    "    # Replace the errors DataFrame dictionaries with a list of their values \n",
    "    for c in dd.columns:\n",
    "        dd[c] = [list(d.values()) for d in dd[c]]\n",
    "    return dd\n"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of indexes created has been limited to 5 ..........................\n"
     ]
    }
   ],
   "source": [
    "collection = 'legit_inst'\n",
    "db = 'owmap'\n",
    "df = read_mongo_to_df(config.uri, db, collection, limit=5)\n",
    "# df = read_mongo_a(config.uri, db, collection, limit=1, squash=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert individual instants to dictionaries(or csv)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def my_learn_function(instant, weather):\n",
    "    print('do a thing with:')\n",
    "    print('weather: ', end='')\n",
    "    pprint(weather)\n",
    "#     print('instant: ', instant)\n",
    "\n",
    "for index, instant in df.groupby(['zipcode', 'instant']):\n",
    "    \n",
    "    my_learn_function(\n",
    "        instant[instant.type == 'forecast'].reset_index().drop(columns=['zipcode', 'instant', 'type']).to_dict('records'),\n",
    "        instant[instant.type == 'weather'].reset_index().drop(columns=['zipcode', 'instant', 'type']).to_dict()\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the error docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in df['weather']:\n",
    "    w.pop('sunset_time', 'sunrise_time')\n",
    "    w.pop('sunrise_time')\n",
    "for l in df['forecasts']:\n",
    "    for f in l:\n",
    "        f.pop('sunset_time', 'sunrise_time')\n",
    "        f.pop('sunrise_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_dict = compare_dicts()\n",
    "errs = []\n",
    "for index, row in df[['forecasts', 'weather']].iterrows():\n",
    "     errs.append(errors(row['forecasts'], row['weather']))\n",
    "df['errs'] = errs\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_keys(dict_list):\n",
    "    ''' Take a list of dictionaries and return a  list of lists of those\n",
    "    dictionary values. \n",
    "    \n",
    "    :param e: a list of dicts\n",
    "    :type e: At least in forecast-forecast the input type will be a pandas\n",
    "    Series, but in general it can take any list-like object of dictionaries.\n",
    "    :return: a list of lists of dict values w/o keys\n",
    "    '''\n",
    "    \n",
    "    values = []\n",
    "    for d in dict_list:\n",
    "        values.append([list(overalls.flatten_dict(dic).values()) for dic in d])\n",
    "    return values\n",
    "\n",
    "err_vals = strip_keys(df['errs'])\n",
    "cast_vals = strip_keys(df['forecasts'])\n",
    "dd = pd.DataFrame([cast_vals, err_vals], index=['forecasts', 'errors'])\n",
    "dd = dd.transpose()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'error_set.csv'\n",
    "dd.to_csv(filename, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> fixdeep
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
